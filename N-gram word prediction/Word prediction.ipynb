{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "01414a2d-4552-4016-8453-4a94b296c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3c279-d96d-4ede-9598-4d1fbffb34f0",
   "metadata": {},
   "source": [
    "Importing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6d328c2c-38a8-4bec-818c-6a1f5e8e9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Aymane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\", \"The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted .\", \"The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr. .\", \"`` Only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\", \"The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' .\"]\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "\n",
    "sentences = [' '.join(words) for words in brown.sents()]\n",
    "\n",
    "print(sentences[:5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae039922-9a31-4fc7-8d26-877d7b471c51",
   "metadata": {},
   "source": [
    "__Corpus Normalization Steps__\n",
    "\n",
    "Before processing any corpus, several steps must be followed to prepare the corpus in a format suitable for analysis. This process is called **normalization**. The steps include:\n",
    "\n",
    "__Case Folding__\n",
    "- Transform the entire corpus content into **lowercase characters** to ensure uniformity.\n",
    "\n",
    "__Tokenization__\n",
    "- Divide the text into smaller units, such as:\n",
    "  - **Words**\n",
    "  - **Subwords**\n",
    "  - **Other entities**\n",
    "- The choice of units depends on various factors, including the algorithm used and the corpus characteristics.\n",
    "\n",
    "__Special Characters Management__\n",
    "- Remove all **punctuation marks**, as I do not consider them as words in this application.\n",
    "- Add two special characters:\n",
    "  - `<s>`: Marks the **start** of a sentence.\n",
    "  - `</s>`: Marks the **end** of a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b37e23ff-e151-45cb-a10c-9c5ba6fc4c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"the fulton county grand jury said friday an investigation of atlanta's recent primary election produced `` no evidence '' that any irregularities took place .\", \"the jury further said in term-end presentments that the city executive committee , which had over-all charge of the election , `` deserves the praise and thanks of the city of atlanta '' for the manner in which the election was conducted .\", \"the september-october term jury had been charged by fulton superior court judge durwood pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by mayor-nominate ivan allen jr. .\", \"`` only a relative handful of such reports was received '' , the jury said , `` considering the widespread interest in the election , the number of voters and the size of this city '' .\", \"the jury said it did find that many of georgia's registration and election laws `` are outmoded or inadequate and often ambiguous '' .\"]\n"
     ]
    }
   ],
   "source": [
    "lower_sentences = [sentence.lower() for sentence in sentences]\n",
    "\n",
    "print(lower_sentences[:5])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec42baf-6cc5-466c-a624-66e58fcb8586",
   "metadata": {},
   "source": [
    "Now I will use regular expressions to match all the non alphanumerical characters and remove them (except the white space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1488ded2-f014-4fb8-9be4-69e8a548c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the fulton county grand jury said friday an investigation of atlanta s recent primary election produced    no evidence    that any irregularities took place  ', 'the jury further said in term end presentments that the city executive committee   which had over all charge of the election      deserves the praise and thanks of the city of atlanta    for the manner in which the election was conducted  ', 'the september october term jury had been charged by fulton superior court judge durwood pye to investigate reports of possible    irregularities    in the hard fought primary which was won by mayor nominate ivan allen jr   ', '   only a relative handful of such reports was received      the jury said      considering the widespread interest in the election   the number of voters and the size of this city     ', 'the jury said it did find that many of georgia s registration and election laws    are outmoded or inadequate and often ambiguous     ']\n"
     ]
    }
   ],
   "source": [
    "cleaned_sentences = [re.sub(r'[^\\w\\s]',' ',sentence) for sentence in lower_sentences]\n",
    "print(cleaned_sentences[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184d9d5-b0fb-45bf-bdfb-7b46614ee364",
   "metadata": {},
   "source": [
    "For the tokenization task, I will use the Punkt tokenizer, a prebuilt and pretrained tokenizer from NLTK. Later, I plan to implement the BPE (Byte Pair Encoding) algorithm, which is another tokenization approach, to demonstrate the steps behind it. For now, I will stick with the Punkt tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f58aefe7-3d12-467e-976a-dc55265a7fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aymane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aymane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Aymane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Aymane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4486349e-413b-4260-9789-7298af8e5fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', 's', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place'], ['the', 'jury', 'further', 'said', 'in', 'term', 'end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', 'which', 'had', 'over', 'all', 'charge', 'of', 'the', 'election', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted'], ['the', 'september', 'october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', 'irregularities', 'in', 'the', 'hard', 'fought', 'primary', 'which', 'was', 'won', 'by', 'mayor', 'nominate', 'ivan', 'allen', 'jr'], ['only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', 'the', 'jury', 'said', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city'], ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgia', 's', 'registration', 'and', 'election', 'laws', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentences = [word_tokenize(sentence)for sentence in cleaned_sentences]\n",
    "print(tokenized_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8b073-cb7b-440b-ad0b-6a9d81565dbf",
   "metadata": {},
   "source": [
    "Now, I add special markers to the beginning and end of each sentence. Note that I add two `<s>` markers at the beginning of each sentence because I will be using a trigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "956696ca-1bf7-4bc7-a721-add6bb888f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<s>', '<s>', 'the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', 's', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place', '</s>'], ['<s>', '<s>', 'the', 'jury', 'further', 'said', 'in', 'term', 'end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', 'which', 'had', 'over', 'all', 'charge', 'of', 'the', 'election', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '</s>'], ['<s>', '<s>', 'the', 'september', 'october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', 'irregularities', 'in', 'the', 'hard', 'fought', 'primary', 'which', 'was', 'won', 'by', 'mayor', 'nominate', 'ivan', 'allen', 'jr', '</s>'], ['<s>', '<s>', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', 'the', 'jury', 'said', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', '</s>'], ['<s>', '<s>', 'the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgia', 's', 'registration', 'and', 'election', 'laws', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', '</s>']]\n"
     ]
    }
   ],
   "source": [
    "normalized_sentences = [['<s>','<s>'] + sentence + ['</s>'] for sentence in tokenized_sentences]\n",
    "print(normalized_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "25fccdd1-97a3-4e43-9329-b255aeb0dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_probability(trigram, trigrams_count, bigrams_count):\n",
    "    trigram_count = trigrams_count.get(trigram, 0)\n",
    "    bigram = (trigram[0], trigram[1])\n",
    "    bigram_count = bigrams_count.get(bigram, 0)\n",
    "    if bigram_count == 0:\n",
    "        return 0\n",
    "    probability = trigram_count / bigram_count\n",
    "    return probability\n",
    "def bigram_probability(bigram, bigrams_count, unigrams_count):\n",
    "    bigram_count = bigrams_count.get(bigram, 0)\n",
    "    unigram = bigram[0]\n",
    "    unigram_count = unigrams_count.get(unigram, 0)\n",
    "    if unigram_count == 0:\n",
    "        return 0\n",
    "    probability = bigram_count / unigram_count\n",
    "    return probability\n",
    "def unigram_probability(word, unigrams_count):\n",
    "    word_count = unigrams_count.get(word, 0)\n",
    "    total_count = sum(unigrams_count.values())\n",
    "    if total_count == 0:\n",
    "        return 0\n",
    "    probability = word_count / total_count\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa0a824-8a1f-4b92-a6be-8c0f1c0e3dbc",
   "metadata": {},
   "source": [
    "Now that I have defined the n-gram probabilities, it is time to implement interpolation smoothing to achieve a better probability distribution. This approach is preferable to the Maximum Likelihood Estimate, which cannot effectively handle zero-probability n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6447cc25-1601-417c-a3dc-f93c7af3d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_interpolation(trigram, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size):\n",
    "    bigram = (trigram[1], trigram[2])\n",
    "    word = trigram[2]  \n",
    "    \n",
    "    p_trigram = trigram_probability(trigram, trigrams_count, bigrams_count)\n",
    "    \n",
    "    p_bigram = bigram_probability(bigram, bigrams_count, unigrams_count)\n",
    "    \n",
    "    p_unigram = unigram_probability(word, unigrams_count)\n",
    "    \n",
    "    p_zerogram = 1 / vocab_size\n",
    "    \n",
    "    probability = t * p_trigram + b * p_bigram + u * p_unigram + z * p_zerogram\n",
    "    \n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af5885-1001-4b2c-bcbc-4d7d95463cc2",
   "metadata": {},
   "source": [
    "Now, I divide the corpus into two sets: a training set and a test set. The training set is used to calculate the probabilities of the n-grams. Here, I will compute all the trigrams, bigrams, and unigrams in the corpus. These will be used for interpolation smoothing to handle zero-probability n-grams and achieve better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "98623c15-69a4-41ec-a82b-3e624336658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus, test_corpus = train_test_split(normalized_sentences, test_size=0.1, random_state=42)\n",
    "train_unigrams = [word for sentence in train_corpus for word in sentence]\n",
    "training_vocab = set(unigrams_count.keys())\n",
    "vocab_size = len(training_vocab)\n",
    "train_bigrams = [bigram for sentence in train_corpus for bigram in ngrams(sentence, 2)]\n",
    "train_trigrams = [trigram for sentence in train_corpus for trigram in ngrams(sentence, 3)]\n",
    "train_unigrams = [word for sentence in train_corpus for word in sentence]\n",
    "\n",
    "bigrams_count = Counter(train_bigrams)\n",
    "trigrams_count = Counter(train_trigrams)\n",
    "unigrams_count = Counter(train_unigrams)\n",
    "\n",
    "test_trigrams = [trigram for sentence in test_corpus for trigram in ngrams(sentence, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ab356-320b-4bdf-9bec-afa5498a99b5",
   "metadata": {},
   "source": [
    "Evaluating a language model is a challenging task. There are two plausible approaches:  \n",
    "\n",
    "Extrinsic Evaluation: This involves assessing the model based on its performance in the specific task it is designed for. In this case, the evaluation focuses on the quality of its predictions.  \n",
    "\n",
    "Intrinsic Evaluation: This approach evaluates the model independently of its specific task. One of the most commonly used metrics for intrinsic evaluation is Perplexity, which measures how 'confused' the model is when predicting the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a4dfdc6a-b4e9-4791-b270-af87a57f863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_trigrams, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size):\n",
    "    log_prob_sum = 0\n",
    "    total_trigrams = len(test_trigrams)\n",
    "\n",
    "    for trigram in test_trigrams:\n",
    "        prob = static_interpolation(trigram, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)\n",
    "        \n",
    "        if prob > 0:\n",
    "            log_prob_sum += math.log2(prob)\n",
    "        else:\n",
    "            log_prob_sum += float('-inf')  \n",
    "\n",
    "    perplexity = 2 ** (-log_prob_sum / total_trigrams)\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5c13a-a66c-4b50-a8a7-b6de68b90ad6",
   "metadata": {},
   "source": [
    "The choice of weights has a significant impact on the performance of the model. There are several methods to determine these parameters, such as the Expectation-Maximization algorithm, which iteratively converges to optimal values. However, to keep it simple, I will try various values and select the ones that perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "eb87b438-63c2-489b-91bd-15d88a00e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 719.3679912031918\n"
     ]
    }
   ],
   "source": [
    "t, b, u, z = 0.5, 0.3, 0.15, 0.05 \n",
    "\n",
    "perplexity = calculate_perplexity(test_trigrams, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "49070170-1dc9-44b8-8bf1-7a4e9c176890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 663.2839835853889\n"
     ]
    }
   ],
   "source": [
    "t, b, u, z = 0.3, 0.5, 0.1, 0.1  \n",
    "\n",
    "perplexity = calculate_perplexity(test_trigrams, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)\n",
    "print(f\"Perplexity: {perplexity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec6210-199f-41ff-899e-7222e45700be",
   "metadata": {},
   "source": [
    "Now let's try an application of this model which is the prediction of the next word. This is used in many applications such as Gmail, when receiving a message or when typing a message the next word is predicted ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "621a01ff-0a78-45f7-8b18-f534b88ea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size):\n",
    "    if len(context) == 2:\n",
    "        w1, w2 = context\n",
    "    elif len(context) == 1:\n",
    "        w1, w2 = '<s>', context[0]\n",
    "    else:\n",
    "        w1, w2 = '<s>', '<s>'\n",
    "\n",
    "    candidates = {}\n",
    "    for word in unigrams_count.keys():\n",
    "        if word == '</s>' or word == '<s>' :  \n",
    "            continue\n",
    "        trigram = (w1, w2, word)\n",
    "        prob = static_interpolation(trigram, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)\n",
    "        candidates[word] = prob\n",
    "\n",
    "    best_word = max(candidates, key=candidates.get)\n",
    "    return best_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07982e8b-00c6-4d7e-86a2-096ba2e257e0",
   "metadata": {},
   "source": [
    "Since we have evaluated the model, we can now train it on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2af0dd20-4016-4622-93b2-a74aedc671bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus =  train_corpus + test_corpus \n",
    "\n",
    "train_unigrams = [word for sentence in train_corpus for word in sentence]\n",
    "training_vocab = set(unigrams_count.keys())\n",
    "vocab_size = len(training_vocab)\n",
    "train_bigrams = [bigram for sentence in train_corpus for bigram in ngrams(sentence, 2)]\n",
    "train_trigrams = [trigram for sentence in train_corpus for trigram in ngrams(sentence, 3)]\n",
    "train_unigrams = [word for sentence in train_corpus for word in sentence]\n",
    "\n",
    "bigrams_count = Counter(train_bigrams)\n",
    "trigrams_count = Counter(train_trigrams)\n",
    "unigrams_count = Counter(train_unigrams)\n",
    "\n",
    "test_trigrams = [trigram for sentence in test_corpus for trigram in ngrams(sentence, 3)]\n",
    "t, b, u, z = 0.3, 0.5, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dd2c2-9eba-499e-a359-4fa5ab823c8e",
   "metadata": {},
   "source": [
    "We choose a context, which means in our case a sequence of two words, and the third word is predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "960109a8-3f7c-46d5-a4c2-7e157ee420d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['i','love']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "020b3eb7-1618-4d4d-a104-3ad5c1af5e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['he','hates']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0984616a-4958-40e9-848e-769ca045711c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'too'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['i','eat']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "aed6242a-5744-455f-876e-3055d91f2009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['the', 'president']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cc00d722-aee3-4545-8c8a-e50761d888dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'most'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['are', 'the']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0612f641-81d1-4773-8ef9-c6a22d90bce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['thank', 'you']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ac83675b-670d-46a7-a40f-0a91c1395c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['the', 'cat']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c39f19da-cfe6-4a08-95eb-5e4f12b472be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['president', 'of']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a188f737-194c-477a-82dd-f19fd9d65fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'united'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['of', 'the']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7c05bd64-3970-4f65-b164-d5235b5dddb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'states'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['the', 'united']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5ee16a2e-a34c-49b0-93d9-1d8587f2f481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hand'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ['the','other']\n",
    "suggest_next_word(context, trigrams_count, bigrams_count, unigrams_count, t, b, u, z, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb94dd2-7dac-4a60-b1e2-93d9b2ed3da8",
   "metadata": {},
   "source": [
    "The predicted words are logical, the task is done correctly :D  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e4a64-4d66-4e4a-981c-c20106e799fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
